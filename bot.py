import os
import telebot
import requests
import datetime
import schedule
import time
import threading
from bs4 import BeautifulSoup
import logging
from flask import Flask
import pytz

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[logging.StreamHandler()]
)
logger = logging.getLogger(__name__)

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
TOKEN = "8067270518:AAFir3k_EuRhNlGF9bD9ER4VHQevld-rquk"
CHANNEL_ID = "@Digital_Fund_1"
CMC_API_KEY = "6316a41d-db32-4e49-a2a3-b66b96c663bf"
REQUEST_TIMEOUT = 30  # –£–≤–µ–ª–∏—á–µ–Ω–Ω—ã–π —Ç–∞–π–º–∞—É—Ç
MOSCOW_TZ = pytz.timezone('Europe/Moscow')
PORT = int(os.getenv('PORT', 10000))

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Flask
app = Flask(__name__)

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±–æ—Ç–∞
bot = telebot.TeleBot(TOKEN, num_threads=1, skip_pending=True)

@app.route('/')
def health_check():
    return "Crypto Bot is Running", 200

def get_current_time():
    return datetime.datetime.now(MOSCOW_TZ)

def fetch_market_data():
    try:
        # CoinGecko –¥–∞–Ω–Ω—ã–µ
        gecko_url = "https://api.coingecko.com/api/v3/global"
        gecko_response = requests.get(gecko_url, timeout=REQUEST_TIMEOUT)
        gecko_response.raise_for_status()
        gecko_data = gecko_response.json()
        
        btc_dominance_gecko = round(gecko_data["data"]["market_cap_percentage"]["btc"], 2)
        total_market_cap_gecko = round(gecko_data["data"]["total_market_cap"]["usd"] / 1e12, 2)

        # CoinMarketCap –¥–∞–Ω–Ω—ã–µ
        cmc_url = "https://pro-api.coinmarketcap.com/v1/global-metrics/quotes/latest"
        cmc_headers = {"X-CMC_PRO_API_KEY": CMC_API_KEY}
        cmc_response = requests.get(cmc_url, headers=cmc_headers, timeout=REQUEST_TIMEOUT)
        cmc_response.raise_for_status()
        cmc_data = cmc_response.json()["data"]
        
        btc_dominance_cmc = round(cmc_data["btc_dominance"], 2)
        total_market_cap_cmc = round(cmc_data["quote"]["USD"]["total_market_cap"] / 1e12, 2)

        return (
            "üìä *–†—ã–Ω–æ—á–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞*\n\n"
            f"‚Ä¢ –û–±—â–∞—è –∫–∞–ø–∏—Ç–∞–ª–∏–∑–∞—Ü–∏—è: ${(total_market_cap_gecko + total_market_cap_cmc)/2:.2f}T\n"
            f"‚Ä¢ –°—Ä–µ–¥–Ω—è—è –¥–æ–º–∏–Ω–∞—Ü–∏—è BTC: {(btc_dominance_gecko + btc_dominance_cmc)/2:.2f}%\n"
            f"‚Ä¢ –î–∞–Ω–Ω—ã–µ: CoinGecko & CoinMarketCap"
        )
    except Exception as e:
        logger.error(f"Market data error: {str(e)}")
        return "üî¥ –†—ã–Ω–æ—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –≤—Ä–µ–º–µ–Ω–Ω–æ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã"

def parse_rbc_news():
    try:
        base_url = "https://www.rbc.ru"
        main_url = f"{base_url}/crypto/"
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/125.0.0.0 Safari/537.36'
        }
        
        response = requests.get(main_url, headers=headers, timeout=REQUEST_TIMEOUT)
        response.raise_for_status()
        soup = BeautifulSoup(response.text, 'html.parser')
        
        # –ê–∫—Ç—É–∞–ª—å–Ω—ã–π —Å–µ–ª–µ–∫—Ç–æ—Ä –¥–ª—è 2024
        article = soup.select_one('.item__wrap.js-news-feed-item:not(.item__wrap--ad)')
        if not article:
            logger.warning("–ù–µ –Ω–∞–π–¥–µ–Ω–æ –∞–∫—Ç—É–∞–ª—å–Ω—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π –Ω–∞ RBK Crypto")
            return None
            
        title = article.select_one('.item__title').text.strip()
        link = article.find('a')['href']
        if not link.startswith('http'):
            link = base_url + link
        
        return {
            'title': title,
            'content': parse_article_content(link),
            'source': 'RBK Crypto',
            'link': link
        }
    except Exception as e:
        logger.error(f"RBK News error: {str(e)}")
        return None

def parse_tradingview_news():
    try:
        url = "https://www.tradingview.com/news/cryptocurrencies/"
        headers = {'User-Agent': 'Mozilla/5.0'}
        
        response = requests.get(url, headers=headers, timeout=REQUEST_TIMEOUT)
        response.raise_for_status()
        soup = BeautifulSoup(response.text, 'html.parser')
        
        article = soup.select_one('.news-item-card')
        if not article:
            return None
            
        title = article.select_one('.title').text.strip()
        link = "https://www.tradingview.com" + article['href']
        description = article.select_one('.description').text.strip()[:300] + "..."
        
        return {
            'title': title,
            'content': description,
            'source': 'TradingView',
            'link': link
        }
    except Exception as e:
        logger.error(f"TradingView News error: {str(e)}")
        return None

def parse_article_content(url):
    try:
        headers = {'User-Agent': 'Mozilla/5.0'}
        response = requests.get(url, headers=headers, timeout=REQUEST_TIMEOUT)
        response.raise_for_status()
        soup = BeautifulSoup(response.text, 'html.parser')
        
        content_blocks = soup.select('.article__text p')
        if not content_blocks:
            return "–ß–∏—Ç–∞—Ç—å –ø–æ–ª–Ω—É—é –≤–µ—Ä—Å–∏—é —Å—Ç–∞—Ç—å–∏ ‚û°Ô∏è"
            
        return ' '.join([p.text.strip() for p in content_blocks[:3]])[:400] + "..."
    except Exception as e:
        logger.error(f"Article parsing error: {str(e)}")
        return "–ß–∏—Ç–∞—Ç—å –ø–æ–ª–Ω—É—é –≤–µ—Ä—Å–∏—é —Å—Ç–∞—Ç—å–∏ ‚û°Ô∏è"

def generate_daily_report():
    try:
        time_now = get_current_time().strftime("%d.%m.%Y %H:%M")
        market_data = fetch_market_data()
        
        return (
            f"üåç *–ï–∂–µ–¥–Ω–µ–≤–Ω—ã–π —Ä—ã–Ω–æ—á–Ω—ã–π –æ—Ç—á–µ—Ç* ({time_now})\n\n"
            f"{market_data}\n\n"
            "#–†—ã–Ω–æ–∫ #–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ #–ê–Ω–∞–ª–∏—Ç–∏–∫–∞"
        )
    except Exception as e:
        logger.error(f"Report generation error: {str(e)}")
        return None

def generate_news_post(news_item):
    try:
        time_now = get_current_time().strftime("%d.%m.%Y %H:%M")
        return (
            f"üì∞ *–ö—Ä–∏–ø—Ç–æ-–Ω–æ–≤–æ—Å—Ç–∏* ({time_now})\n\n"
            f"üè∑ *{news_item['title']}*\n"
            f"{news_item['content']}\n\n"
            f"üîç –ò—Å—Ç–æ—á–Ω–∏–∫: {news_item['source']}\n"
            f"üîó [–ß–∏—Ç–∞—Ç—å –ø–æ–ª–Ω–æ—Å—Ç—å—é]({news_item['link']})\n\n"
            "#–ù–æ–≤–æ—Å—Ç–∏ #–ê–Ω–∞–ª–∏—Ç–∏–∫–∞"
        )
    except Exception as e:
        logger.error(f"News post error: {str(e)}")
        return None

def send_post(post, is_news=False):
    try:
        if not post:
            logger.warning("–ü—É—Å—Ç–æ–π –ø–æ—Å—Ç, –æ—Ç–ø—Ä–∞–≤–∫–∞ –æ—Ç–º–µ–Ω–µ–Ω–∞")
            return
            
        logger.info("–ù–∞—á–∞–ª–æ –æ—Ç–ø—Ä–∞–≤–∫–∏ –ø–æ—Å—Ç–∞...")
        bot.send_message(
            chat_id=CHANNEL_ID,
            text=post,
            parse_mode="Markdown",
            disable_web_page_preview=not is_news
        )
        logger.info("–ü–æ—Å—Ç —É—Å–ø–µ—à–Ω–æ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω")
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏: {str(e)}")

def schedule_tasks():
    logger.info("–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Ä–∞—Å–ø–∏—Å–∞–Ω–∏—è...")
    
    # –†—ã–Ω–æ—á–Ω—ã–µ –æ—Ç—á–µ—Ç—ã –≤ 08:00 –∏ 22:00 –ø–æ –ú–æ—Å–∫–≤–µ
    schedule.every().day.at("08:00").do(lambda: send_post(generate_daily_report())).tag('reports')
    schedule.every().day.at("22:00").do(lambda: send_post(generate_daily_report())).tag('reports')
    
    # –ù–æ–≤–æ—Å—Ç–∏ –∫–∞–∂–¥—ã–π —á–∞—Å —Å 09:00 –¥–æ 21:00 –ø–æ –ú–æ—Å–∫–≤–µ
    for hour in range(9, 22):
        schedule.every().day.at(f"{hour:02d}:00").do(post_news_update).tag('news')
    
    logger.info(f"–ó–∞–ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∑–∞–¥–∞—á–∏: {schedule.get_jobs()}")

def post_news_update():
    try:
        logger.info(f"üöÄ –ó–∞–ø—É—Å–∫ –Ω–æ–≤–æ—Å—Ç–Ω–æ–π –∑–∞–¥–∞—á–∏ –≤ {get_current_time().strftime('%H:%M:%S')}")
        
        # –ß–µ—Ä–µ–¥—É–µ–º –∏—Å—Ç–æ—á–Ω–∏–∫–∏ —Å –∑–∞–¥–µ—Ä–∂–∫–æ–π
        sources = ['rbc', 'tradingview']
        for source in sources:
            time.sleep(2)  # –ó–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º–∏
            news_item = fetch_news(source)
            if news_item:
                post = generate_news_post(news_item)
                if post:
                    send_post(post, is_news=True)
                    time.sleep(3)  # –ü–∞—É–∑–∞ –º–µ–∂–¥—É –ø–æ—Å—Ç–∞–º–∏
            else:
                logger.warning(f"–ù–æ–≤–æ—Å—Ç–∏ –∏–∑ {source} –Ω–µ –ø–æ–ª—É—á–µ–Ω—ã")
                
    except Exception as e:
        logger.error(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –≤ –∑–∞–¥–∞—á–µ: {str(e)}")

def fetch_news(source):
    try:
        if source == "rbc":
            return parse_rbc_news()
        elif source == "tradingview":
            return parse_tradingview_news()
        return None
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –Ω–æ–≤–æ—Å—Ç–µ–π ({source}): {str(e)}")
        return None

def run_scheduler():
    logger.info("–ó–∞–ø—É—Å–∫ –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫–∞...")
    while True:
        try:
            schedule.run_pending()
            time.sleep(1)
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫–∞: {str(e)}")
            time.sleep(10)

if __name__ == "__main__":
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –≤—Ä–µ–º–µ–Ω–Ω–æ–π –∑–æ–Ω—ã
    os.environ['TZ'] = 'Europe/Moscow'
    time.tzset()
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫–∞
    schedule_tasks()
    
    # –ó–∞–ø—É—Å–∫ –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫–∞ –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø–æ—Ç–æ–∫–µ
    scheduler_thread = threading.Thread(target=run_scheduler, daemon=True)
    scheduler_thread.start()
    
    # –û—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª
    logger.info("ü§ñ –ë–æ—Ç —É—Å–ø–µ—à–Ω–æ –∑–∞–ø—É—â–µ–Ω")
    try:
        while True:
            time.sleep(3600)
    except KeyboardInterrupt:
        logger.info("–û—Å—Ç–∞–Ω–æ–≤–∫–∞ –±–æ—Ç–∞...")
